//===========================================================================
// File shunting script for S3. Use this JavaScript as a lambda function
// triggered by the creation of an object in an S3 bucket. The script will
// match the object name against a list of mappings, and if it finds a match
// it will copy the object to the destination specified in the mapping. The
// source pattern is a regular expression, and the destination pattern is a
// string that can include groupings ($1, $2 etc.) from the match against the
// source pattern.
//
// To achieve a linear step-by-step flow JS promises are used for every step.
// There are alternatives to this, such as passing completion functions to
// asynchronous operations, but an imperative style is easier to read and
// debug, not only by the Ops team this was written for (who were more
// familiar with bash than JavaScript) but for me too.
//
// In the production environment this code was found to be triggered by
// unexpected events eventually traced to S3FS, which caused an unwanted
// file creation event for a zero-byte file at the point the file started
// to be written, as well as the event we wanted when the file was ready to
// be processed. For this reason there are a couple of hacks to detect
// zero-byte files and file-not-found exceptions. These are nasty and should
// be removed when possible.
//
// Contact: john.reah@johnreah.com
// Updated: 03-July-2018
//===========================================================================

'use strict';

var AWS = require('aws-sdk');

var emailsToNotifyOnError = ['john.reah+aws@johnreah.com'];
var emailSender = 'john.reah+aws@johnreah.com';
var mappings = [
    {
        name: "Test mapping",
        sourcePattern: /(.*)(HappyFace.jpg)(.*)/,
        destinationBucket: "johnreah-bucket02",
        destinationPattern: "blah-$2-blah",
        emailsToNotify: ['john.reah+aws@johnreah.com']
    },
    {
        // Example incoming file: customer_name/incoming/PRODUCTS_WEEKLY_20180703
        // Destination after move: johnreah-bucket02/products/ready/PRODUCTS_WEEKLY_20180703
        name: "Products mapping",
        sourcePattern: /(customer_name\/incoming\/)(PRODUCTS_WEEKLY)(.*)/,
        destinationBucket: "johnreah-bucket02",
        destinationPattern: "products/ready/$2$3",
        emailsToNotify: ['john.reah+aws@johnreah.com']
    },
    {
        name: "Orders mapping",
        sourcePattern: /(customer_name\/incoming\/)(ORDERS_DAILY)(.*)/,
        destinationBucket: "johnreah-bucket02",
        destinationPattern: "orders/ready/$2$3",
        emailsToNotify: ['john.reah+aws@johnreah.com']
    },
    {
        name: "Users mapping",
        sourcePattern: /(customer_name\/incoming\/)(USERS)(.*)/,
        destinationBucket: "johnreah-bucket02",
        destinationPattern: "users/ready/$2$3",
        emailsToNotify: ['john.reah+aws@johnreah.com']
    }
];

exports.handler = async function (event, context, callback) {
    for (var i = 0; i < event.Records.length; i++) {
        await processRecord(event.Records[i], context, callback);
    }
};

async function processRecord(record, context, callback) {
    
    var logMessages = "";
    function log(msg) {
        console.log(msg);
        logMessages = logMessages.concat(msg, "\n");
    }

    log("INCOMING: " + record.s3.object.key);
    
    if (/processed\//.test(record.s3.object.key)) {
        log("IGNORING processed file " + record.s3.object.key);
        return;
    }
    
    var matchFound = false, exceptionCaught = false;
    for (var i = 0; i < mappings.length; i++) {
        if (mappings[i].sourcePattern.test(record.s3.object.key)) {
            matchFound = true;
            log("MAPPING: " + mappings[i].name);
            log("PATTERN: " + mappings[i].sourcePattern.toString());
            log("SOURCE FILE SIZE: " + record.s3.object.size);
            
            if (record.s3.object.size == 0) {
                log("Source file size is 0 - probably generated by S3FS - skipping");
                continue;
            }
            
            var destinationKey = record.s3.object.key.replace(mappings[i].sourcePattern, mappings[i].destinationPattern);

            try {
                log("Calling copy to destination");
                await promiseToCopyFileToDestination(record.s3.bucket.name, record.s3.object.key, mappings[i].destinationBucket, destinationKey);

                log("Checking destination file size");
                let headObject = await promiseToGetHeadObject(mappings[i].destinationBucket, destinationKey);
                log("DESTINATION FILE SIZE: " + headObject.ContentLength);
                if (headObject.ContentLength != record.s3.object.size)
                    throw new Error("Size error: expected " + record.s3.object.size + ", got " + headObject.ContentLength + ". Bailing.");

                log("Calling copy to archive");
                await promiseToCopyFileToArchive(record.s3.bucket.name, record.s3.object.key);
                
                log("Calling deleteFile");
                await promiseToDeleteFile(record.s3.bucket.name, record.s3.object.key);
                
                log("Calling sendEmail");
                await promiseToSendEmail(mappings[i].emailsToNotify, "S3: " + record.s3.object.key, logMessages);

            } catch(err) {
                log("EXCEPTION: " + err.message);

                if (err.message == "The specified key does not exist.") {
                    log("Exception probably due to duplicate event fired by S3FS - bailing.")
                    continue;
                }

                exceptionCaught = true;
            }
        }
    }
    if (!matchFound) {
        log("NO MATCH FOUND for " + record.s3.object.key);
        await promiseToSendEmail(emailsToNotifyOnError, "S3 NO MATCH: " + record.s3.object.key, logMessages);
    }
    else if (exceptionCaught) {
        await promiseToSendEmail(emailsToNotifyOnError, "S3 ERROR: " + record.s3.object.key, logMessages);
    }
    return;
    
    function promiseToCopyFileToDestination(sourceBucket, sourceKey, destinationBucket, destinationKey) {
        log("COPYING TO DESTINATION: " + destinationKey);
        return promiseToCopyFile(sourceBucket, sourceKey, destinationBucket, destinationKey);
    }

    function promiseToCopyFileToArchive(bucketName, fileKey) {
        var sourcePattern = /(.*)(incoming\/)(.*)/;
        if (sourcePattern.test(fileKey)) {
            var processedKey = fileKey.replace(sourcePattern, "$1$2processed/$3");
            log("COPYING TO ARCHIVE: " + processedKey);
            return promiseToCopyFile(bucketName, fileKey, bucketName, processedKey);
        } else {
            return Promise.resolve();
        }
    }

    function promiseToCopyFile(sourceBucket, sourceKey, destinationBucket, destinationKey) {
        var s3 = new AWS.S3();
        var params = {
            CopySource: sourceBucket + "/" + sourceKey,
            Bucket: destinationBucket,
            Key: destinationKey
        };
        return s3.copyObject(params).promise();
    }
    
    function promiseToDeleteFile(bucket, key) {
        log("DELETING: " + key);

        var s3 = new AWS.S3();
        var params = {
            Bucket: bucket,
            Key: key
        };
        return s3.deleteObject(params).promise();
    }

    function promiseToSendEmail(recipients, subject, body) {
        log("SENDING EMAIL TO: " + recipients);

        var SES = new AWS.SES();
        var params = {
            Source: emailSender,
            Destination: { ToAddresses: recipients },
            Message: {
                Subject: { Data: subject },
                Body: { Text: { Data: body } }
            }
        };
        return SES.sendEmail(params).promise();
    }

    function promiseToGetHeadObject(bucket, key) {
        log("GETTING OBJECT INFO: " + key);

        var s3 = new AWS.S3();
        var params = {
            Bucket: bucket,
            Key: key
        };
        return s3.headObject(params).promise();
    }

}

